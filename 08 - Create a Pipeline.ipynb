{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Pipeline\n",
    "\n",
    "You can perform the various steps required to ingest data, train a model, and register the model individually by using the Azure ML SDK to run script-based experiments. However, in an enterprise environment it is common to encapsulate the sequence of discrete steps required to build a machine learning solution into a *pipeline* that can be run on one or more compute targets, either on-demand by a user, from an automated build process, or on a schedule.\n",
    "\n",
    "In this notebook, you'll bring together all of these elements to create a simple pipeline that pre-processes data and then trains and registers a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "To get started, connect to your workspace.\n",
    "\n",
    "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.24.0 to work with AML\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config(\".\\\\Working_Files\\\\config.json\")\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "In your pipeline, you'll use a dataset containing details of diabetes patients. Run the cell below to create this dataset (if you created it in previously, the code will find the existing version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'diabetes dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
    "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='diabetes dataset',\n",
    "                                description='diabetes data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create scripts for pipeline steps\n",
    "\n",
    "Pipelines consist of one or more *steps*, which can be Python scripts, or specialized steps like a data transfer step that copies data from one location to another. Each step can run in its own compute context. In this exercise, you'll build a simple pipeline that contains two Python script steps: one to pre-process some training data, and another to use the pre-processed data to train and register a model.\n",
    "\n",
    "First, let's create a folder for the script files we'll use in the pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'diabetes_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the first script, which will read data from the diabetes dataset and apply some simple pre-processing to remove any rows with missing data and normalize the numeric features so they're on a similar scale.\n",
    "\n",
    "The script includes a argument named **--prepped-data**, which references the folder where the resulting data should be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_pipeline/prep_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/prep_diabetes.py\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from azureml.core import Run\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
    "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
    "args = parser.parse_args()\n",
    "save_folder = args.prepped_data\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
    "\n",
    "# Log raw row count\n",
    "row_count = (len(diabetes))\n",
    "run.log('raw_rows', row_count)\n",
    "\n",
    "# remove nulls\n",
    "diabetes = diabetes.dropna()\n",
    "\n",
    "# Normalize the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
    "diabetes[num_cols] = scaler.fit_transform(diabetes[num_cols])\n",
    "\n",
    "# Log processed rows\n",
    "row_count = (len(diabetes))\n",
    "run.log('processed_rows', row_count)\n",
    "\n",
    "# Save the prepped data\n",
    "print(\"Saving Data...\")\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_path = os.path.join(save_folder,'data.csv')\n",
    "diabetes.to_csv(save_path, index=False, header=True)\n",
    "\n",
    "# End the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the script for the second step, which will train a model. The script includes a argument named **--training-folder**, which references the folder where the prepared data was saved by the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_pipeline/train_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/train_diabetes.py\n",
    "# Import libraries\n",
    "from azureml.core import Run, Model\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--training-folder\", type=str, dest='training_folder', help='training data folder')\n",
    "args = parser.parse_args()\n",
    "training_folder = args.training_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the prepared data file in the training folder\n",
    "print(\"Loading Data...\")\n",
    "file_path = os.path.join(training_folder,'data.csv')\n",
    "diabetes = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train adecision tree model\n",
    "print('Training a decision tree model...')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "run.log_image(name = \"ROC\", plot = fig)\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "print(\"Saving model...\")\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "model_file = os.path.join('outputs', 'diabetes_model.pkl')\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "\n",
    "# Register the model\n",
    "print('Registering model...')\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path = model_file,\n",
    "               model_name = 'diabetes_model',\n",
    "               tags={'Training context':'Pipeline'},\n",
    "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\n",
    "\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a compute environment for the pipeline steps\n",
    "\n",
    "In this exercise, you'll use the same compute for both steps, but it's important to realize that each step is run independently; so you could specify different compute contexts for each step if appropriate.\n",
    "\n",
    "First, get the compute target you created in a previous lab (if it doesn't exist, it will be created).\n",
    "\n",
    "> **Important**: Change *your-compute-cluster* to the name of your compute cluster in the code below before running it! Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"LC-ML-Cluster-1\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compute will require a Python environment with the necessary package dependencies installed, so you'll need to create a run configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "diabetes_env = Environment(\"diabetes-pipeline-env\")\n",
    "diabetes_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "diabetes_env.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a set of package dependencies\n",
    "diabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn','ipykernel','matplotlib','pandas','pip'],\n",
    "                                             pip_packages=['azureml-defaults','azureml-dataprep[pandas]','pyarrow'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "diabetes_env.python.conda_dependencies = diabetes_packages\n",
    "\n",
    "# Register the environment \n",
    "diabetes_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'diabetes-pipeline-env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run a pipeline\n",
    "\n",
    "Now you're ready to create and run a pipeline.\n",
    "\n",
    "First you need to define the steps for the pipeline, and any data references that need to passed between them. In this case, the first step must write the prepared data to a folder that can be read from by the second step. Since the steps will be run on remote compute (and in fact, could each be run on different compute), the folder path must be passed as a data reference to a location in a datastore within the workspace. The **PipelineData** object is a special kind of data reference that is used for interim storage locations that can be passed between pipeline steps, so you'll create one and use at as the output for the first step and the input for the second step. Note that you also need to pass it as a script argument so our code can access the datastore location referenced by the data reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "prepped_data_folder = PipelineData(\"prepped_data_folder\", datastore=ws.get_default_datastore())\n",
    "\n",
    "# Step 1, Run the data prep script\n",
    "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"prep_diabetes.py\",\n",
    "                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n",
    "                                             '--prepped-data', prepped_data_folder],\n",
    "                                outputs=[prepped_data_folder],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "# Step 2, run the training script\n",
    "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"train_diabetes.py\",\n",
    "                                arguments = ['--training-folder', prepped_data_folder],\n",
    "                                inputs=[prepped_data_folder],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, you're ready build the pipeline from the steps you've defined and run it as an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Prepare Data [2933ce2d][4adac236-318c-40fb-8876-b62c81d6f157], (This step will run and generate new outputs)\n",
      "Created step Train and Register Model [8d07ea08][685c2d40-34f2-499b-a252-ca5d59b7c494], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 839bcf5f-efd9-4cc6-b8a7-e2811a5f5139\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/mslearn-diabetes-pipeline/runs/839bcf5f-efd9-4cc6-b8a7-e2811a5f5139?wsid=/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourcegroups/ML/workspaces/AML\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9631aeebb28f46b695d26e84bf43e2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/mslearn-diabetes-pipeline/runs/839bcf5f-efd9-4cc6-b8a7-e2811a5f5139?wsid=/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourcegroups/ML/workspaces/AML\", \"run_id\": \"839bcf5f-efd9-4cc6-b8a7-e2811a5f5139\", \"run_properties\": {\"run_id\": \"839bcf5f-efd9-4cc6-b8a7-e2811a5f5139\", \"created_utc\": \"2021-03-20T05:47:34.682952Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-03-20T06:03:18.982022Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.839bcf5f-efd9-4cc6-b8a7-e2811a5f5139/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=Zl4NpNQ7Dnyx8HChhw%2FjWiGyp59SNiH3nbVkZYqcbU0%3D&st=2021-03-20T05%3A38%3A00Z&se=2021-03-20T13%3A48%3A00Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.839bcf5f-efd9-4cc6-b8a7-e2811a5f5139/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=cnmL6DUBAwf9qvUBsKUluVGGicnnmIvQ1H3nMaghfUg%3D&st=2021-03-20T05%3A38%3A00Z&se=2021-03-20T13%3A48%3A00Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.839bcf5f-efd9-4cc6-b8a7-e2811a5f5139/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=n6e6X7sziYJU0%2FpXsm80abdg%2Fd90SMxXhx32iK7k2xM%3D&st=2021-03-20T05%3A38%3A00Z&se=2021-03-20T13%3A48%3A00Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:15:44\", \"run_number\": \"1\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"ab5354f8-0dee-456f-b706-9cad66aacd39\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-03-20T05:59:48.170396Z\", \"created_time\": \"2021-03-20T05:47:38.781665Z\", \"end_time\": \"2021-03-20T06:02:12.859006Z\", \"duration\": \"0:14:34\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-03-20T05:47:38.781665Z\", \"is_reused\": \"\"}, {\"run_id\": \"883b2975-6847-4f4d-9f4c-ad8e1f619fdd\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-03-20T06:02:29.976023Z\", \"created_time\": \"2021-03-20T06:02:19.282161Z\", \"end_time\": \"2021-03-20T06:03:13.942861Z\", \"duration\": \"0:00:54\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-03-20T06:02:19.282161Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-03-20 05:47:38Z] Submitting 1 runs, first five are: 2933ce2d:ab5354f8-0dee-456f-b706-9cad66aacd39\\n[2021-03-20 06:02:18Z] Completing processing run id ab5354f8-0dee-456f-b706-9cad66aacd39.\\n[2021-03-20 06:02:19Z] Submitting 1 runs, first five are: 8d07ea08:883b2975-6847-4f4d-9f4c-ad8e1f619fdd\\n[2021-03-20 06:03:18Z] Completing processing run id 883b2975-6847-4f4d-9f4c-ad8e1f619fdd.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"df013c29\": {\"node_id\": \"df013c29\", \"name\": \"diabetes dataset\"}}, \"module_nodes\": {\"2933ce2d\": {\"node_id\": \"2933ce2d\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"ab5354f8-0dee-456f-b706-9cad66aacd39\"}, \"8d07ea08\": {\"node_id\": \"8d07ea08\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"883b2975-6847-4f4d-9f4c-ad8e1f619fdd\"}}, \"edges\": [{\"source_node_id\": \"df013c29\", \"source_node_name\": \"diabetes dataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"2933ce2d\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"2933ce2d\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data_folder\", \"target_name\": \"prepped_data_folder\", \"dst_node_id\": \"8d07ea08\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"ab5354f8-0dee-456f-b706-9cad66aacd39\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-03-20T05:59:48.170396Z\", \"created_time\": \"2021-03-20T05:47:38.781665Z\", \"end_time\": \"2021-03-20T06:02:12.859006Z\", \"duration\": \"0:14:34\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-03-20T05:47:38.781665Z\", \"is_reused\": \"\"}, {\"run_id\": \"883b2975-6847-4f4d-9f4c-ad8e1f619fdd\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-03-20T06:02:29.976023Z\", \"created_time\": \"2021-03-20T06:02:19.282161Z\", \"end_time\": \"2021-03-20T06:03:13.942861Z\", \"duration\": \"0:00:54\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-03-20T06:02:19.282161Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.24.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 839bcf5f-efd9-4cc6-b8a7-e2811a5f5139\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/mslearn-diabetes-pipeline/runs/839bcf5f-efd9-4cc6-b8a7-e2811a5f5139?wsid=/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourcegroups/ML/workspaces/AML\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: ab5354f8-0dee-456f-b706-9cad66aacd39\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/mslearn-diabetes-pipeline/runs/ab5354f8-0dee-456f-b706-9cad66aacd39?wsid=/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourcegroups/ML/workspaces/AML\n",
      "StepRun( Prepare Data ) Status: NotStarted\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2021/03/20 05:47:50 Downloading source code...\n",
      "2021/03/20 05:47:52 Finished downloading source code\n",
      "2021/03/20 05:47:52 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2021/03/20 05:47:52 Successfully set up Docker network: acb_default_network\n",
      "2021/03/20 05:47:52 Setting up Docker configuration...\n",
      "2021/03/20 05:47:53 Successfully set up Docker configuration\n",
      "2021/03/20 05:47:53 Logging in to registry: 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io\n",
      "2021/03/20 05:47:54 Successfully logged into 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io\n",
      "2021/03/20 05:47:54 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/03/20 05:47:54 Scanning for dependencies...\n",
      "2021/03/20 05:47:55 Successfully scanned dependencies\n",
      "2021/03/20 05:47:55 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "\n",
      "Step 1/18 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210220.v1@sha256:45f047999ab2ced61a2fd0cf8d8421f796ca05b8423c1a0ac652791a321bff9a\n",
      "sha256:45f047999ab2ced61a2fd0cf8d8421f796ca05b8423c1a0ac652791a321bff9a: Pulling from azureml/intelmpi2018.3-ubuntu16.04\n",
      "4007a89234b4: Already exists\n",
      "5dfa26c6b9c9: Already exists\n",
      "0ba7bf18aa40: Already exists\n",
      "4c6ec688ebe3: Already exists\n",
      "a2874ccdee09: Pulling fs layer\n",
      "84e6fa394f53: Pulling fs layer\n",
      "cde35e537c55: Pulling fs layer\n",
      "08224915e098: Pulling fs layer\n",
      "3e72e2b08f2a: Pulling fs layer\n",
      "503a95eb7b7f: Pulling fs layer\n",
      "cac267f3f656: Pulling fs layer\n",
      "9c9189719fce: Pulling fs layer\n",
      "08224915e098: Waiting\n",
      "3e72e2b08f2a: Waiting\n",
      "503a95eb7b7f: Waiting\n",
      "cac267f3f656: Waiting\n",
      "9c9189719fce: Waiting\n",
      "84e6fa394f53: Verifying Checksum\n",
      "84e6fa394f53: Download complete\n",
      "cde35e537c55: Verifying Checksum\n",
      "cde35e537c55: Download complete\n",
      "a2874ccdee09: Verifying Checksum\n",
      "a2874ccdee09: Download complete\n",
      "503a95eb7b7f: Verifying Checksum\n",
      "503a95eb7b7f: Download complete\n",
      "cac267f3f656: Verifying Checksum\n",
      "cac267f3f656: Download complete\n",
      "08224915e098: Verifying Checksum\n",
      "08224915e098: Download complete\n",
      "9c9189719fce: Verifying Checksum\n",
      "9c9189719fce: Download complete\n",
      "3e72e2b08f2a: Verifying Checksum\n",
      "3e72e2b08f2a: Download complete\n",
      "a2874ccdee09: Pull complete\n",
      "84e6fa394f53: Pull complete\n",
      "cde35e537c55: Pull complete\n",
      "StepRun( Prepare Data ) Status: Running\n",
      "08224915e098: Pull complete\n",
      "3e72e2b08f2a: Pull complete\n",
      "503a95eb7b7f: Pull complete\n",
      "cac267f3f656: Pull complete\n",
      "9c9189719fce: Pull complete\n",
      "Digest: sha256:45f047999ab2ced61a2fd0cf8d8421f796ca05b8423c1a0ac652791a321bff9a\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210220.v1@sha256:45f047999ab2ced61a2fd0cf8d8421f796ca05b8423c1a0ac652791a321bff9a\n",
      " ---> b79635653e9e\n",
      "Step 2/18 : USER root\n",
      " ---> Running in 22bb0a7a7cc4\n",
      "Removing intermediate container 22bb0a7a7cc4\n",
      " ---> a20156723e9b\n",
      "Step 3/18 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 248ce2987d2b\n",
      "Removing intermediate container 248ce2987d2b\n",
      " ---> 271dae6d9fe2\n",
      "Step 4/18 : WORKDIR /\n",
      " ---> Running in dcb4d1f32738\n",
      "Removing intermediate container dcb4d1f32738\n",
      " ---> 0abefdd0c7d1\n",
      "Step 5/18 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 8f7e159224c1\n",
      "Step 6/18 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in fbbb3b177200\n",
      "Removing intermediate container fbbb3b177200\n",
      " ---> 59b456791c92\n",
      "Step 7/18 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 9928a251eac3\n",
      "Step 8/18 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 2a416c83c91f\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... \n",
      "done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "mkl_fft-1.2.0        | 164 KB    |            |   0% \n",
      "mkl_fft-1.2.0        | 164 KB    | ########## | 100% \n",
      "\n",
      "wcwidth-0.2.5        | 37 KB     |            |   0% \n",
      "wcwidth-0.2.5        | 37 KB     | ########## | 100% \n",
      "\n",
      "ipykernel-5.3.4      | 176 KB    |            |   0% \n",
      "ipykernel-5.3.4      | 176 KB    | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
      "\n",
      "prompt-toolkit-3.0.8 | 244 KB    |            |   0% \n",
      "prompt-toolkit-3.0.8 | 244 KB    | ########## | 100% \n",
      "\n",
      "fontconfig-2.13.0    | 291 KB    |            |   0% \n",
      "fontconfig-2.13.0    | 291 KB    | ########## | 100% \n",
      "\n",
      "joblib-0.17.0        | 205 KB    |            |   0% \n",
      "joblib-0.17.0        | 205 KB    | ########## | 100% \n",
      "\n",
      "icu-58.2             | 22.7 MB   |            |   0% \n",
      "icu-58.2             | 22.7 MB   | ###4       |  35% \n",
      "icu-58.2             | 22.7 MB   | ########7  |  88% \n",
      "icu-58.2             | 22.7 MB   | ########## | 100% \n",
      "\n",
      "pandas-1.1.3         | 10.5 MB   |            |   0% \n",
      "pandas-1.1.3         | 10.5 MB   | ########3  |  83% \n",
      "pandas-1.1.3         | 10.5 MB   | ########## | 100% \n",
      "\n",
      "zeromq-4.3.3         | 678 KB    |            |   0% \n",
      "zeromq-4.3.3         | 678 KB    | ########## | 100% \n",
      "\n",
      "traitlets-4.3.3      | 137 KB    |            |   0% \n",
      "traitlets-4.3.3      | 137 KB    | ########## | 100% \n",
      "\n",
      "mkl-service-2.3.0    | 208 KB    |            |   0% \n",
      "mkl-service-2.3.0    | 208 KB    | ########## | 100% \n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "\n",
      "pygments-2.7.1       | 704 KB    |            |   0% \n",
      "pygments-2.7.1       | 704 KB    | ########## | 100% \n",
      "\n",
      "jupyter_core-4.6.3   | 75 KB     |            |   0% \n",
      "jupyter_core-4.6.3   | 75 KB     | ########## | 100% \n",
      "\n",
      "zstd-1.4.4           | 1006 KB   |            |   0% \n",
      "zstd-1.4.4           | 1006 KB   | ########## | 100% \n",
      "\n",
      "threadpoolctl-2.1.0  | 16 KB     |            |   0% \n",
      "threadpoolctl-2.1.0  | 16 KB     | ########## | 100% \n",
      "\n",
      "ptyprocess-0.6.0     | 23 KB     |            |   0% \n",
      "ptyprocess-0.6.0     | 23 KB     | ########## | 100% \n",
      "\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    |            |   0% \n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \n",
      "\n",
      "jedi-0.17.2          | 952 KB    |            |   0% \n",
      "jedi-0.17.2          | 952 KB    | ########## | 100% \n",
      "\n",
      "libuuid-1.0.3        | 16 KB     |            |   0% \n",
      "libuuid-1.0.3        | 16 KB     | ########## | 100% \n",
      "\n",
      "sip-4.19.24          | 297 KB    |            |   0% \n",
      "sip-4.19.24          | 297 KB    | ########## | 100% \n",
      "\n",
      "qt-5.9.6             | 86.7 MB   |            |   0% \n",
      "qt-5.9.6             | 86.7 MB   | 6          |   6% \n",
      "qt-5.9.6             | 86.7 MB   | #9         |  19% \n",
      "qt-5.9.6             | 86.7 MB   | ###        |  31% \n",
      "qt-5.9.6             | 86.7 MB   | ####2      |  43% \n",
      "qt-5.9.6             | 86.7 MB   | #####6     |  56% \n",
      "qt-5.9.6             | 86.7 MB   | #######    |  70% \n",
      "qt-5.9.6             | 86.7 MB   | ########3  |  84% \n",
      "qt-5.9.6             | 86.7 MB   | #########7 |  97% \n",
      "\n",
      "qt-5.9.6             | 86.7 MB   | ########## | 100% \n",
      "\n",
      "numpy-1.19.1         | 20 KB     |            |   0% \n",
      "numpy-1.19.1         | 20 KB     | ########## | 100% \n",
      "\n",
      "decorator-4.4.2      | 14 KB     |            |   0% \n",
      "decorator-4.4.2      | 14 KB     | ########## | 100% \n",
      "\n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \n",
      "mkl-2019.4           | 204.1 MB  | 4          |   4% \n",
      "mkl-2019.4           | 204.1 MB  | 9          |  10% \n",
      "mkl-2019.4           | 204.1 MB  | #5         |  15% \n",
      "mkl-2019.4           | 204.1 MB  | ##         |  20% \n",
      "mkl-2019.4           | 204.1 MB  | ##5        |  25% \n",
      "mkl-2019.4           | 204.1 MB  | ###        |  31% \n",
      "mkl-2019.4           | 204.1 MB  | ###6       |  36% \n",
      "mkl-2019.4           | 204.1 MB  | ####2      |  42% \n",
      "mkl-2019.4           | 204.1 MB  | ####8      |  48% \n",
      "mkl-2019.4           | 204.1 MB  | #####3     |  54% \n",
      "mkl-2019.4           | 204.1 MB  | #####9     |  60% \n",
      "mkl-2019.4           | 204.1 MB  | ######5    |  65% \n",
      "mkl-2019.4           | 204.1 MB  | #######    |  71% \n",
      "mkl-2019.4           | 204.1 MB  | #######6   |  76% \n",
      "mkl-2019.4           | 204.1 MB  | ########1  |  82% \n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  88% \n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \n",
      "mkl-2019.4           | 204.1 MB  | #########9 |  99% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mkl-2019.4           | 204.1 MB  | ########## | 100% \n",
      "\n",
      "gst-plugins-base-1.1 | 6.3 MB    |            |   0% \n",
      "gst-plugins-base-1.1 | 6.3 MB    | ########## | 100% \n",
      "\n",
      "intel-openmp-2020.2  | 947 KB    |            |   0% \n",
      "intel-openmp-2020.2  | 947 KB    | ########## | 100% \n",
      "\n",
      "ipython-7.16.1       | 1.1 MB    |            |   0% \n",
      "ipython-7.16.1       | 1.1 MB    | ########## | 100% \n",
      "\n",
      "libpng-1.6.37        | 364 KB    |            |   0% \n",
      "libpng-1.6.37        | 364 KB    | ########## | 100% \n",
      "\n",
      "gstreamer-1.14.0     | 3.8 MB    |            |   0% \n",
      "gstreamer-1.14.0     | 3.8 MB    | ########## | 100% \n",
      "\n",
      "pillow-8.0.0         | 675 KB    |            |   0% \n",
      "pillow-8.0.0         | 675 KB    | ########## | 100% \n",
      "\n",
      "wheel-0.35.1         | 36 KB     |            |   0% \n",
      "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
      "\n",
      "libxcb-1.14          | 610 KB    |            |   0% \n",
      "libxcb-1.14          | 610 KB    | ########## | 100% \n",
      "\n",
      "cycler-0.10.0        | 13 KB     |            |   0% \n",
      "cycler-0.10.0        | 13 KB     | ########## | 100% \n",
      "\n",
      "pyparsing-2.4.7      | 64 KB     |            |   0% \n",
      "pyparsing-2.4.7      | 64 KB     | ########## | 100% \n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \n",
      "blas-1.0             | 6 KB      | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "\n",
      "freetype-2.10.4      | 901 KB    |            |   0% \n",
      "freetype-2.10.4      | 901 KB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 128 KB    |            |   0% \n",
      "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
      "\n",
      "jupyter_client-6.1.7 | 76 KB     |            |   0% \n",
      "jupyter_client-6.1.7 | 76 KB     | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "\n",
      "libsodium-1.0.18     | 387 KB    |            |   0% \n",
      "libsodium-1.0.18     | 387 KB    | ########## | 100% \n",
      "\n",
      "libtiff-4.1.0        | 607 KB    |            |   0% \n",
      "libtiff-4.1.0        | 607 KB    | ########## | 100% \n",
      "\n",
      "matplotlib-3.3.1     | 24 KB     |            |   0% \n",
      "matplotlib-3.3.1     | 24 KB     | ########## | 100% \n",
      "\n",
      "six-1.15.0           | 13 KB     |            |   0% \n",
      "six-1.15.0           | 13 KB     | ########## | 100% \n",
      "\n",
      "backcall-0.2.0       | 14 KB     |            |   0% \n",
      "backcall-0.2.0       | 14 KB     | ########## | 100% \n",
      "\n",
      "pip-20.2.4           | 2.0 MB    |            |   0% \n",
      "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
      "\n",
      "glib-2.56.2          | 5.0 MB    |            |   0% \n",
      "glib-2.56.2          | 5.0 MB    | ########## | 100% \n",
      "\n",
      "olefile-0.46         | 48 KB     |            |   0% \n",
      "olefile-0.46         | 48 KB     | ########## | 100% \n",
      "\n",
      "pickleshare-0.7.5    | 13 KB     |            |   0% \n",
      "pickleshare-0.7.5    | 13 KB     | ########## | 100% \n",
      "\n",
      "dbus-1.13.18         | 586 KB    |            |   0% \n",
      "dbus-1.13.18         | 586 KB    | ########## | 100% \n",
      "\n",
      "libxml2-2.9.10       | 1.3 MB    |            |   0% \n",
      "libxml2-2.9.10       | 1.3 MB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "\n",
      "expat-2.2.10         | 192 KB    |            |   0% \n",
      "expat-2.2.10         | 192 KB    | ########## | 100% \n",
      "\n",
      "scikit-learn-0.23.2  | 6.9 MB    |            |   0% \n",
      "scikit-learn-0.23.2  | 6.9 MB    | #######6   |  76% \n",
      "scikit-learn-0.23.2  | 6.9 MB    | ########## | 100% \n",
      "\n",
      "parso-0.7.0          | 71 KB     |            |   0% \n",
      "parso-0.7.0          | 71 KB     | ########## | 100% \n",
      "\n",
      "pyzmq-19.0.2         | 479 KB    |            |   0% \n",
      "pyzmq-19.0.2         | 479 KB    | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #######9   |  79% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "\n",
      "scipy-1.5.2          | 18.5 MB   |            |   0% \n",
      "scipy-1.5.2          | 18.5 MB   | ###6       |  36% \n",
      "scipy-1.5.2          | 18.5 MB   | ########7  |  87% \n",
      "scipy-1.5.2          | 18.5 MB   | ########## | 100% \n",
      "\n",
      "pyqt-5.9.2           | 5.6 MB    |            |   0% \n",
      "pyqt-5.9.2           | 5.6 MB    | #######2   |  73% \n",
      "pyqt-5.9.2           | 5.6 MB    | ########## | 100% \n",
      "\n",
      "matplotlib-base-3.3. | 6.7 MB    |            |   0% \n",
      "matplotlib-base-3.3. | 6.7 MB    | ########8  |  88% \n",
      "matplotlib-base-3.3. | 6.7 MB    | ########## | 100% \n",
      "\n",
      "certifi-2020.6.20    | 160 KB    |            |   0% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "\n",
      "pexpect-4.8.0        | 84 KB     |            |   0% \n",
      "pexpect-4.8.0        | 84 KB     | ########## | 100% \n",
      "\n",
      "setuptools-50.3.0    | 891 KB    |            |   0% \n",
      "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "\n",
      "lcms2-2.11           | 419 KB    |            |   0% \n",
      "lcms2-2.11           | 419 KB    | ########## | 100% \n",
      "\n",
      "lz4-c-1.9.2          | 203 KB    |            |   0% \n",
      "lz4-c-1.9.2          | 203 KB    | ########## | 100% \n",
      "\n",
      "pytz-2020.1          | 239 KB    |            |   0% \n",
      "pytz-2020.1          | 239 KB    | ########## | 100% \n",
      "\n",
      "kiwisolver-1.2.0     | 91 KB     |            |   0% \n",
      "kiwisolver-1.2.0     | 91 KB     | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \n",
      "python-3.6.2         | 27.0 MB   | #9         |  19% \n",
      "python-3.6.2         | 27.0 MB   | #####6     |  56% \n",
      "python-3.6.2         | 27.0 MB   | #########6 |  97% \n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
      "\n",
      "tk-8.6.10            | 3.2 MB    |            |   0% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "\n",
      "tornado-6.0.4        | 650 KB    |            |   0% \n",
      "tornado-6.0.4        | 650 KB    | ########## | 100% \n",
      "\n",
      "pcre-8.44            | 269 KB    |            |   0% \n",
      "pcre-8.44            | 269 KB    | ########## | 100% \n",
      "\n",
      "ipython_genutils-0.2 | 39 KB     |            |   0% \n",
      "ipython_genutils-0.2 | 39 KB     | ########## | 100% \n",
      "\n",
      "numpy-base-1.19.1    | 5.2 MB    |            |   0% \n",
      "numpy-base-1.19.1    | 5.2 MB    | ########## | 100% \n",
      "\n",
      "mkl_random-1.1.0     | 369 KB    |            |   0% \n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \n",
      "\n",
      "python-dateutil-2.8. | 224 KB    |            |   0% \n",
      "python-dateutil-2.8. | 224 KB    | ########## | 100% \n",
      "\n",
      "jpeg-9b              | 247 KB    |            |   0% \n",
      "jpeg-9b              | 247 KB    | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "\n",
      "libffi-3.2.1         | 52 KB     |            |   0% \n",
      "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.4w5zy5wh.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.24.0-py3-none-any.whl (3.1 kB)\n",
      "Collecting azureml-dataprep[pandas]\n",
      "  Downloading azureml_dataprep-2.13.0-py3-none-any.whl (39.4 MB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-3.0.0-cp36-cp36m-manylinux2014_x86_64.whl (20.7 MB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.24.0\n",
      "  Downloading azureml_dataset_runtime-1.24.0-py3-none-any.whl (3.4 kB)\n",
      "Collecting werkzeug<=1.0.1,>=0.16.1\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting azureml-core~=1.24.0\n",
      "  Downloading azureml_core-1.24.0.post2-py3-none-any.whl (2.2 MB)\n",
      "Collecting azureml-dataprep-native<33.0.0,>=32.0.0\n",
      "  Downloading azureml_dataprep_native-32.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting cloudpickle<2.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting azureml-dataprep-rslex<1.12.0a,>=1.11.0dev0\n",
      "  Downloading azureml_dataprep_rslex-1.11.0-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Collecting azure-identity<1.5.0,>=1.2.0\n",
      "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.20-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
      "Requirement already satisfied, skipping upgrade: pandas<2.0.0,>=0.23.4; extra == \"pandas\" in /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/lib/python3.6/site-packages (from azureml-dataprep[pandas]->-r /azureml-environment-setup/condaenv.4w5zy5wh.requirements.txt (line 2)) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>=1.14.0; extra == \"pandas\" in /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/lib/python3.6/site-packages (from azureml-dataprep[pandas]->-r /azureml-environment-setup/condaenv.4w5zy5wh.requirements.txt (line 2)) (1.19.1)\n",
      "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-2.11.3-py2.py3-none-any.whl (125 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.4w5zy5wh.requirements.txt (line 1)) (1.15.0)\n",
      "Collecting requests>=2.17.3\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting adal>=0.4.5\n",
      "  Downloading adal-1.2.6-py2.py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.4w5zy5wh.requirements.txt (line 1)) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.3 in /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.4w5zy5wh.requirements.txt (line 1)) (2.8.1)\n",
      "Collecting dill>=0.2.7.1\n",
      "  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting PyJWT<3.0.0\n",
      "  Downloading PyJWT-2.0.1-py3-none-any.whl (15 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting ruamel.yaml>=0.15.35\n",
      "  Downloading ruamel.yaml-0.16.13-py2.py3-none-any.whl (111 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-12.1.0-py2.py3-none-any.whl (1.1 MB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.26-py2.py3-none-any.whl (12 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting pyopenssl<21.0.0\n",
      "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
      "  Downloading cryptography-3.4.6-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting msal-extensions~=0.2.2\n",
      "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting msal<2.0.0,>=1.3.0\n",
      "  Downloading msal-1.10.0-py2.py3-none-any.whl (60 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.12.0-py2.py3-none-any.whl (130 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux2010_x86_64.whl (32 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/lib/python3.6/site-packages (from requests>=2.17.3->azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.4w5zy5wh.requirements.txt (line 1)) (2020.6.20)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n",
      "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.58.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-3.7.3-py3-none-any.whl (12 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
      "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Building wheels for collected packages: json-logging-py, fusepy, liac-arff\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=a2c96fe974588aedbe369964e88d28dc06330039c4f75dc8fd16ab8b6672cfa8\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=0fae6d3fde3f9cd204ef02101853aaaa5a93109412cbbb828a8f407ef4c11ae0\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11730 sha256=43861eac8d6e7becfdedbac1d29394fdbbb52a021a0482d48dbd44327686197c\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\n",
      "Successfully built json-logging-py fusepy liac-arff\n",
      "Installing collected packages: json-logging-py, gunicorn, configparser, azureml-dataprep-native, cloudpickle, azureml-dataprep-rslex, pycparser, cffi, cryptography, PyJWT, chardet, urllib3, idna, requests, msal, portalocker, msal-extensions, azure-core, azure-identity, distro, dotnetcore2, pyarrow, azureml-dataprep, fusepy, azureml-dataset-runtime, werkzeug, MarkupSafe, Jinja2, itsdangerous, click, flask, applicationinsights, adal, dill, liac-arff, azureml-model-management-sdk, backports.weakref, backports.tempfile, oauthlib, requests-oauthlib, isodate, msrest, msrestazure, jmespath, azure-common, azure-mgmt-storage, ruamel.yaml.clib, ruamel.yaml, azure-mgmt-authorization, websocket-client, docker, jeepney, SecretStorage, azure-mgmt-resource, typing-extensions, zipp, importlib-metadata, jsonpickle, pathspec, pyasn1, pyopenssl, ndg-httpsclient, contextlib2, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-graphrbac, azureml-core, azureml-defaults\n",
      "Successfully installed Jinja2-2.11.3 MarkupSafe-1.1.1 PyJWT-2.0.1 SecretStorage-3.3.1 adal-1.2.6 applicationinsights-0.11.9 azure-common-1.1.26 azure-core-1.12.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-12.1.0 azure-mgmt-storage-11.2.0 azureml-core-1.24.0.post2 azureml-dataprep-2.13.0 azureml-dataprep-native-32.0.0 azureml-dataprep-rslex-1.11.0 azureml-dataset-runtime-1.24.0 azureml-defaults-1.24.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.5 chardet-4.0.0 click-7.1.2 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-3.4.6 dill-0.3.3 distro-1.5.0 docker-4.4.4 dotnetcore2-2.1.20 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.10 importlib-metadata-3.7.3 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.6.0 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.0.0 liac-arff-2.5.0 msal-1.10.0 msal-extensions-0.2.2 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.1.0 pathspec-0.8.1 portalocker-1.7.1 pyarrow-3.0.0 pyasn1-0.4.8 pycparser-2.20 pyopenssl-20.0.1 requests-2.25.1 requests-oauthlib-1.3.0 ruamel.yaml-0.16.13 ruamel.yaml.clib-0.2.2 typing-extensions-3.7.4.3 urllib3-1.26.4 websocket-client-0.58.0 werkzeug-1.0.1 zipp-3.4.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.7.12\n",
      "  latest version: 4.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "WARNING: /root/.conda/pkgs does not exist\n",
      "Removing intermediate container 2a416c83c91f\n",
      " ---> b7984de47a55\n",
      "Step 9/18 : ENV PATH /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin:$PATH\n",
      " ---> Running in fbeed9e372d1\n",
      "Removing intermediate container fbeed9e372d1\n",
      " ---> 170e906efe54\n",
      "Step 10/18 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> 6af969d6d49e\n",
      "Step 11/18 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> b2cf66a0f2a6\n",
      "Step 12/18 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472\n",
      " ---> Running in 0a3a1307d8fb\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container 0a3a1307d8fb\n",
      " ---> 88ef600272ab\n",
      "Step 13/18 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472\n",
      " ---> Running in ce0f872ec62e\n",
      "Removing intermediate container ce0f872ec62e\n",
      " ---> 599d68a41764\n",
      "Step 14/18 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 1efdf9f194e5\n",
      "Removing intermediate container 1efdf9f194e5\n",
      " ---> 58ca4cd4dede\n",
      "Step 15/18 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 1b59af29ccbb\n",
      "Step 16/18 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in b915652e6f8f\n",
      "Removing intermediate container b915652e6f8f\n",
      " ---> 3b3a829fb6f4\n",
      "Step 17/18 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 1388da2c66bf\n",
      "Removing intermediate container 1388da2c66bf\n",
      " ---> 0849a999767c\n",
      "Step 18/18 : CMD [\"bash\"]\n",
      " ---> Running in 8613a8b9fa00\n",
      "Removing intermediate container 8613a8b9fa00\n",
      " ---> b912cefd342c\n",
      "Successfully built b912cefd342c\n",
      "Successfully tagged 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25:latest\n",
      "Successfully tagged 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25:1\n",
      "2021/03/20 05:53:12 Successfully executed container: acb_step_0\n",
      "2021/03/20 05:53:12 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/03/20 05:53:12 Pushing image: 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25:1, attempt 1\n",
      "The push refers to repository [05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25]\n",
      "830b23b860f2: Preparing\n",
      "3394d55305d1: Preparing\n",
      "edbb9bb7644c: Preparing\n",
      "70ca3305fc17: Preparing\n",
      "f3f868afd289: Preparing\n",
      "44f8e60f5399: Preparing\n",
      "e6eeb9ba8b0c: Preparing\n",
      "6906d5301ada: Preparing\n",
      "5875904bd3b7: Preparing\n",
      "303a8fd39764: Preparing\n",
      "2d9074798077: Preparing\n",
      "710fe8abc588: Preparing\n",
      "fcf8f624203c: Preparing\n",
      "5b068a34ffe7: Preparing\n",
      "51a74f86a3cf: Preparing\n",
      "95474adf3c5c: Preparing\n",
      "846cc75ad492: Preparing\n",
      "5276d2b930fc: Preparing\n",
      "e6feec0db89a: Preparing\n",
      "697949baa658: Preparing\n",
      "935c56d8b3f9: Preparing\n",
      "44f8e60f5399: Waiting\n",
      "e6eeb9ba8b0c: Waiting\n",
      "6906d5301ada: Waiting\n",
      "5875904bd3b7: Waiting\n",
      "303a8fd39764: Waiting\n",
      "2d9074798077: Waiting\n",
      "710fe8abc588: Waiting\n",
      "fcf8f624203c: Waiting\n",
      "5b068a34ffe7: Waiting\n",
      "51a74f86a3cf: Waiting\n",
      "95474adf3c5c: Waiting\n",
      "846cc75ad492: Waiting\n",
      "5276d2b930fc: Waiting\n",
      "e6feec0db89a: Waiting\n",
      "697949baa658: Waiting\n",
      "935c56d8b3f9: Waiting\n",
      "70ca3305fc17: Pushed\n",
      "830b23b860f2: Pushed\n",
      "edbb9bb7644c: Pushed\n",
      "3394d55305d1: Pushed\n",
      "5875904bd3b7: Pushed\n",
      "6906d5301ada: Pushed\n",
      "44f8e60f5399: Pushed\n",
      "e6eeb9ba8b0c: Pushed\n",
      "303a8fd39764: Pushed\n",
      "2d9074798077: Pushed\n",
      "710fe8abc588: Pushed\n",
      "95474adf3c5c: Pushed\n",
      "51a74f86a3cf: Pushed\n",
      "fcf8f624203c: Pushed\n",
      "5276d2b930fc: Pushed\n",
      "e6feec0db89a: Pushed\n",
      "697949baa658: Pushed\n",
      "5b068a34ffe7: Pushed\n",
      "\n",
      "846cc75ad492: Pushed\n",
      "935c56d8b3f9: Pushed\n",
      "f3f868afd289: Pushed\n",
      "1: digest: sha256:5c4d65be8a1ac024c92c7ee4b1f2f84cb18730527e6b5d6dad14058668b79459 size: 4721\n",
      "2021/03/20 05:56:09 Successfully pushed image: 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25:1\n",
      "2021/03/20 05:56:09 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/03/20 05:56:09 Pushing image: 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25:latest, attempt 1\n",
      "The push refers to repository [05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25]\n",
      "830b23b860f2: Preparing\n",
      "3394d55305d1: Preparing\n",
      "edbb9bb7644c: Preparing\n",
      "70ca3305fc17: Preparing\n",
      "f3f868afd289: Preparing\n",
      "44f8e60f5399: Preparing\n",
      "e6eeb9ba8b0c: Preparing\n",
      "6906d5301ada: Preparing\n",
      "5875904bd3b7: Preparing\n",
      "303a8fd39764: Preparing\n",
      "2d9074798077: Preparing\n",
      "710fe8abc588: Preparing\n",
      "fcf8f624203c: Preparing\n",
      "5b068a34ffe7: Preparing\n",
      "51a74f86a3cf: Preparing\n",
      "95474adf3c5c: Preparing\n",
      "846cc75ad492: Preparing\n",
      "5276d2b930fc: Preparing\n",
      "e6feec0db89a: Preparing\n",
      "697949baa658: Preparing\n",
      "935c56d8b3f9: Preparing\n",
      "44f8e60f5399: Waiting\n",
      "e6eeb9ba8b0c: Waiting\n",
      "6906d5301ada: Waiting\n",
      "5875904bd3b7: Waiting\n",
      "303a8fd39764: Waiting\n",
      "2d9074798077: Waiting\n",
      "710fe8abc588: Waiting\n",
      "fcf8f624203c: Waiting\n",
      "5b068a34ffe7: Waiting\n",
      "51a74f86a3cf: Waiting\n",
      "95474adf3c5c: Waiting\n",
      "846cc75ad492: Waiting\n",
      "5276d2b930fc: Waiting\n",
      "e6feec0db89a: Waiting\n",
      "697949baa658: Waiting\n",
      "935c56d8b3f9: Waiting\n",
      "f3f868afd289: Layer already exists\n",
      "830b23b860f2: Layer already exists\n",
      "70ca3305fc17: Layer already exists\n",
      "edbb9bb7644c: Layer already exists\n",
      "3394d55305d1: Layer already exists\n",
      "6906d5301ada: Layer already exists\n",
      "44f8e60f5399: Layer already exists\n",
      "5875904bd3b7: Layer already exists\n",
      "e6eeb9ba8b0c: Layer already exists\n",
      "710fe8abc588: Layer already exists\n",
      "303a8fd39764: Layer already exists\n",
      "2d9074798077: Layer already exists\n",
      "95474adf3c5c: Layer already exists\n",
      "51a74f86a3cf: Layer already exists\n",
      "fcf8f624203c: Layer already exists\n",
      "846cc75ad492: Layer already exists\n",
      "5b068a34ffe7: Layer already exists\n",
      "e6feec0db89a: Layer already exists\n",
      "935c56d8b3f9: Layer already exists\n",
      "697949baa658: Layer already exists\n",
      "5276d2b930fc: Layer already exists\n",
      "latest: digest: sha256:5c4d65be8a1ac024c92c7ee4b1f2f84cb18730527e6b5d6dad14058668b79459 size: 4721\n",
      "2021/03/20 05:56:16 Successfully pushed image: 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25:latest\n",
      "2021/03/20 05:56:16 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 318.226495)\n",
      "2021/03/20 05:56:16 Populating digests for step ID: acb_step_0...\n",
      "2021/03/20 05:56:19 Successfully populated digests for step ID: acb_step_0\n",
      "2021/03/20 05:56:19 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 176.149280)\n",
      "2021/03/20 05:56:19 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 6.956553)\n",
      "2021/03/20 05:56:19 The following dependencies were found:\n",
      "2021/03/20 05:56:19 \n",
      "- image:\n",
      "    registry: 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io\n",
      "    repository: azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25\n",
      "    tag: latest\n",
      "    digest: sha256:5c4d65be8a1ac024c92c7ee4b1f2f84cb18730527e6b5d6dad14058668b79459\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
      "    tag: 20210220.v1\n",
      "    digest: sha256:45f047999ab2ced61a2fd0cf8d8421f796ca05b8423c1a0ac652791a321bff9a\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io\n",
      "    repository: azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25\n",
      "    tag: \"1\"\n",
      "    digest: sha256:5c4d65be8a1ac024c92c7ee4b1f2f84cb18730527e6b5d6dad14058668b79459\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/intelmpi2018.3-ubuntu16.04\n",
      "    tag: 20210220.v1\n",
      "    digest: sha256:45f047999ab2ced61a2fd0cf8d8421f796ca05b8423c1a0ac652791a321bff9a\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: cb3 was successful after 8m30s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt\n",
      "========================================================================================================================\n",
      "2021-03-20T05:59:51Z Starting output-watcher...\n",
      "2021-03-20T05:59:51Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-03-20T05:59:51Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2021-03-20T05:59:52Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25\n",
      "4007a89234b4: Pulling fs layer\n",
      "5dfa26c6b9c9: Pulling fs layer\n",
      "0ba7bf18aa40: Pulling fs layer\n",
      "4c6ec688ebe3: Pulling fs layer\n",
      "a2874ccdee09: Pulling fs layer\n",
      "84e6fa394f53: Pulling fs layer\n",
      "cde35e537c55: Pulling fs layer\n",
      "08224915e098: Pulling fs layer\n",
      "3e72e2b08f2a: Pulling fs layer\n",
      "503a95eb7b7f: Pulling fs layer\n",
      "cac267f3f656: Pulling fs layer\n",
      "9c9189719fce: Pulling fs layer\n",
      "d7554a81b9f3: Pulling fs layer\n",
      "f593ccc9b7ad: Pulling fs layer\n",
      "772b85aab2a0: Pulling fs layer\n",
      "216468766907: Pulling fs layer\n",
      "a58e06d9d0fd: Pulling fs layer\n",
      "917e121fec6d: Pulling fs layer\n",
      "a74435cb33b8: Pulling fs layer\n",
      "ee7fb7d0764b: Pulling fs layer\n",
      "d0234b59dac2: Pulling fs layer\n",
      "84e6fa394f53: Waiting\n",
      "cde35e537c55: Waiting\n",
      "08224915e098: Waiting\n",
      "3e72e2b08f2a: Waiting\n",
      "503a95eb7b7f: Waiting\n",
      "cac267f3f656: Waiting\n",
      "9c9189719fce: Waiting\n",
      "d7554a81b9f3: Waiting\n",
      "f593ccc9b7ad: Waiting\n",
      "772b85aab2a0: Waiting\n",
      "216468766907: Waiting\n",
      "a58e06d9d0fd: Waiting\n",
      "917e121fec6d: Waiting\n",
      "a74435cb33b8: Waiting\n",
      "ee7fb7d0764b: Waiting\n",
      "d0234b59dac2: Waiting\n",
      "4c6ec688ebe3: Waiting\n",
      "a2874ccdee09: Waiting\n",
      "0ba7bf18aa40: Verifying Checksum\n",
      "0ba7bf18aa40: Download complete\n",
      "5dfa26c6b9c9: Download complete\n",
      "4c6ec688ebe3: Download complete\n",
      "4007a89234b4: Verifying Checksum\n",
      "4007a89234b4: Download complete\n",
      "84e6fa394f53: Verifying Checksum\n",
      "84e6fa394f53: Download complete\n",
      "a2874ccdee09: Verifying Checksum\n",
      "a2874ccdee09: Download complete\n",
      "cde35e537c55: Verifying Checksum\n",
      "cde35e537c55: Download complete\n",
      "08224915e098: Verifying Checksum\n",
      "08224915e098: Download complete\n",
      "cac267f3f656: Verifying Checksum\n",
      "cac267f3f656: Download complete\n",
      "503a95eb7b7f: Verifying Checksum\n",
      "503a95eb7b7f: Download complete\n",
      "9c9189719fce: Verifying Checksum\n",
      "9c9189719fce: Download complete\n",
      "d7554a81b9f3: Verifying Checksum\n",
      "d7554a81b9f3: Download complete\n",
      "3e72e2b08f2a: Verifying Checksum\n",
      "3e72e2b08f2a: Download complete\n",
      "772b85aab2a0: Verifying Checksum\n",
      "772b85aab2a0: Download complete\n",
      "f593ccc9b7ad: Verifying Checksum\n",
      "f593ccc9b7ad: Download complete\n",
      "216468766907: Verifying Checksum\n",
      "216468766907: Download complete\n",
      "917e121fec6d: Verifying Checksum\n",
      "917e121fec6d: Download complete\n",
      "a74435cb33b8: Verifying Checksum\n",
      "a74435cb33b8: Download complete\n",
      "4007a89234b4: Pull complete\n",
      "ee7fb7d0764b: Verifying Checksum\n",
      "ee7fb7d0764b: Download complete\n",
      "5dfa26c6b9c9: Pull complete\n",
      "0ba7bf18aa40: Pull complete\n",
      "d0234b59dac2: Verifying Checksum\n",
      "d0234b59dac2: Download complete\n",
      "4c6ec688ebe3: Pull complete\n",
      "a2874ccdee09: Pull complete\n",
      "84e6fa394f53: Pull complete\n",
      "a58e06d9d0fd: Verifying Checksum\n",
      "a58e06d9d0fd: Download complete\n",
      "cde35e537c55: Pull complete\n",
      "08224915e098: Pull complete\n",
      "3e72e2b08f2a: Pull complete\n",
      "503a95eb7b7f: Pull complete\n",
      "cac267f3f656: Pull complete\n",
      "9c9189719fce: Pull complete\n",
      "d7554a81b9f3: Pull complete\n",
      "f593ccc9b7ad: Pull complete\n",
      "772b85aab2a0: Pull complete\n",
      "216468766907: Pull complete\n",
      "a58e06d9d0fd: Pull complete\n",
      "917e121fec6d: Pull complete\n",
      "a74435cb33b8: Pull complete\n",
      "ee7fb7d0764b: Pull complete\n",
      "d0234b59dac2: Pull complete\n",
      "Digest: sha256:5c4d65be8a1ac024c92c7ee4b1f2f84cb18730527e6b5d6dad14058668b79459\n",
      "Status: Downloaded newer image for 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25:latest\n",
      "05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25:latest\n",
      "2021-03-20T06:01:18Z Check if container ab5354f8-0dee-456f-b706-9cad66aacd39 already exist exited with 0, \n",
      "\n",
      "471d6a65250c6cbe845cf8817512dc568af535ce3546d676d8ad465589227ed1\n",
      "2021/03/20 06:01:21 Starting App Insight Logger for task:  containerSetup\n",
      "2021/03/20 06:01:21 Version: 3.0.01524.0008 Branch: .SourceBranch Commit: eba29f9\n",
      "2021/03/20 06:01:21 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/03/20 06:01:21 Starting infiniband setup\n",
      "2021/03/20 06:01:21 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/03/20 06:01:21 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/03/20 06:01:21 Starting setupPasswordLessSSH setup\n",
      "2021/03/20 06:01:21 sshd runtime has already been installed in the container\n",
      "ssh-keygen: /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "2021/03/20 06:01:21 All App Insights Logs was send successfully\n",
      "2021/03/20 06:01:21 App Insight Client has already been closed\n",
      "2021/03/20 06:01:21 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-03-20T06:01:21Z Starting docker container succeeded.\n",
      "2021-03-20T06:01:27Z Job environment preparation succeeded on 10.0.0.5. Output: \n",
      ">>>   2021/03/20 05:59:44 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2021/03/20 05:59:44 Version: 3.0.01524.0008 Branch: .SourceBranch Commit: eba29f9\n",
      ">>>   2021/03/20 05:59:44 runtime.GOOS linux\n",
      ">>>   2021/03/20 05:59:44 Reading dyanamic configs\n",
      ">>>   2021/03/20 05:59:44 Container sas url: https://baiscriptswesteuropeprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=9UBH7ig8b9NIeIkNQpNxDmP7wUMtSqFoIE5AY22cheE%3D\n",
      ">>>   2021/03/20 05:59:44 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables: no such file or directory\n",
      ">>>   2021/03/20 05:59:44 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installed false, isEnable false,\n",
      ">>>   2021/03/20 05:59:44 azsecpack isEnable:false,GetDisableVsatlsscan:true\n",
      ">>>   2021/03/20 05:59:44 [doTurnOffAzsecpack] output:   Active: inactive (dead)\n",
      ">>>   ,err:<nil>.\n",
      ">>>   2021/03/20 05:59:44 OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2021/03/20 05:59:44 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
      ">>>   2021/03/20 05:59:44 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/03/20 05:59:44 GPU count found on the node: 0\n",
      ">>>   2021/03/20 05:59:44 AMLComputeXDSEndpoint:  https://westeurope-prodk8ds.batchai.core.windows.net\n",
      ">>>   2021/03/20 05:59:44 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2021/03/20 05:59:44 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/config\n",
      ">>>   2021/03/20 05:59:44 This is not a aml-workstation (compute instance), current offer type: azureml. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2021/03/20 05:59:44 Starting identity responder.\n",
      ">>>   2021/03/20 05:59:44 Starting identity responder.\n",
      ">>>   2021/03/20 05:59:44 Failed to open file /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/config/.batchai.IdentityResponder.envlist: open /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
      ">>>   2021/03/20 05:59:44 Logfile used for identity responder: /mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/IdentityResponderLog-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt\n",
      ">>>   2021/03/20 05:59:44 Logfile used for identity responder: /mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/IdentityResponderLog-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt\n",
      ">>>   2021/03/20 05:59:44 Started Identity Responder for job.\n",
      ">>>   2021/03/20 05:59:44 Started Identity Responder for job.\n",
      ">>>   2021/03/20 05:59:44 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/wd\n",
      ">>>   2021/03/20 05:59:44 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/shared\n",
      ">>>   2021/03/20 05:59:44 Mounting job level file systems\n",
      ">>>   2021/03/20 05:59:44 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts\n",
      ">>>   2021/03/20 05:59:44 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/config/.amlcompute.datastorecredentials\n",
      ">>>   2021/03/20 05:59:44 Datastore credentials file not found, skipping.\n",
      ">>>   2021/03/20 05:59:44 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/config/.master.runtimesastokens\n",
      ">>>   2021/03/20 05:59:44 Runtime sas tokens file not found, skipping.\n",
      ">>>   2021/03/20 05:59:44 No NFS configured\n",
      ">>>   2021/03/20 05:59:44 No Azure File Shares configured\n",
      ">>>   2021/03/20 05:59:44 Mounting blob file systems\n",
      ">>>   2021/03/20 05:59:44 Blobfuse runtime version 1.3.6\n",
      ">>>   2021/03/20 05:59:44 Mounting azureml-blobstore-05ae1289-f7d6-4452-89be-e0b8433bc9bc container from aml1914939045 account at /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore\n",
      ">>>   2021/03/20 05:59:44 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/03/20 05:59:44 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/03/20 05:59:44 Blobfuse cache size set to 24972 MB.\n",
      ">>>   2021/03/20 05:59:44 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=24972 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/03/20 05:59:44 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore\n",
      ">>>   2021/03/20 05:59:44 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore\n",
      ">>>   2021/03/20 05:59:45 Successfully mounted azureml-blobstore-05ae1289-f7d6-4452-89be-e0b8433bc9bc container from aml1914939045 account at /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore\n",
      ">>>   2021/03/20 05:59:45 No unmanaged file systems configured\n",
      ">>>   2021/03/20 05:59:45 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/03/20 05:59:45 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/03/20 05:59:45 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/azureml_compute_logs\n",
      ">>>   2021/03/20 05:59:46 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/logs\n",
      ">>>   2021/03/20 05:59:47 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/outputs\n",
      ">>>   2021/03/20 05:59:49 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 12\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/03/20 05:59:51 Starting output-watcher...\n",
      ">>>   2021/03/20 05:59:51 Single file input dataset is enabled.\n",
      ">>>   2021/03/20 05:59:51 Start to pulling docker image: 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25\n",
      ">>>   2021/03/20 05:59:51 Start pull docker image: 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io\n",
      ">>>   2021/03/20 05:59:51 Getting credentials for image 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25 with url 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io\n",
      ">>>   2021/03/20 05:59:51 Container registry is ACR.\n",
      ">>>   2021/03/20 05:59:51 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/03/20 05:59:51 Getting ACR Credentials from EMS for environment diabetes-pipeline-env:1\n",
      ">>>   2021/03/20 05:59:51 Requesting XDS for registry details.\n",
      ">>>   2021/03/20 05:59:51 Attempt 1 of http call to https://westeurope-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourceGroups/ml/workspaces/aml/clusters/lc-ml-cluster-1/nodes/tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d?api-version=2018-02-01\n",
      ">>>   2021/03/20 05:59:51 Got container registry details from credentials service for registry address: 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io.\n",
      ">>>   2021/03/20 05:59:51 Writing ACR Details to file...\n",
      ">>>   2021/03/20 05:59:51 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/03/20 05:59:51 Executing 'Copy ACR Details file' on 10.0.0.5\n",
      ">>>   2021/03/20 05:59:52 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/03/20 05:59:52 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/03/20 05:59:52 Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/03/20 05:59:52 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/03/20 05:59:52 EMS returned 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io for environment diabetes-pipeline-env\n",
      ">>>   2021/03/20 05:59:52 start login to the docker registry\n",
      ">>>   2021/03/20 05:59:52 Successfully logged into the docker registry.\n",
      ">>>   2021/03/20 05:59:52 Start run pull docker image command\n",
      ">>>   2021/03/20 05:59:54 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 6\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/03/20 06:01:18 Pull docker image succeeded.\n",
      ">>>   2021/03/20 06:01:18 Pull docker image time: 1m27.254261626s\n",
      ">>>   \n",
      ">>>   2021/03/20 06:01:18 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/03/20 06:01:18 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/03/20 06:01:18 Setting the memory limit for docker container to be 13675 MB\n",
      ">>>   2021/03/20 06:01:18 The env variable file size is 37915 bytes\n",
      ">>>   2021/03/20 06:01:18 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/03/20 06:01:18 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,ab5354f8-0dee-456f-b706-9cad66aacd39,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/certs:/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,13675m,-v,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/wd:/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39:/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/config/.batchai.envlist,--shm-size,2g\n",
      ">>>   2021/03/20 06:01:18 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
      ">>>   2021/03/20 06:01:18 the binding /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39:/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39 \n",
      ">>>   2021/03/20 06:01:18 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,ab5354f8-0dee-456f-b706-9cad66aacd39,-m,13675m,-w,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/config/.batchai.envlist,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39:/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39,-v,/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/wd:/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/wd,-v,/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/certs:/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/certs\n",
      ">>>   2021/03/20 06:01:18 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name ab5354f8-0dee-456f-b706-9cad66aacd39 -m 13675m -w /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/config/.batchai.envlist --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39:/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39 -v /mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/wd:/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/wd -v /mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/certs:/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/certs -d -it --privileged --net=host 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25\n",
      ">>>   2021/03/20 06:01:18 Check if container ab5354f8-0dee-456f-b706-9cad66aacd39 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/03/20 06:01:18 Check if container ab5354f8-0dee-456f-b706-9cad66aacd39 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/03/20 06:01:19 Attempt 1 of http call to https://westeurope.experiments.azureml.net/history/v1.0/private/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourceGroups/ML/providers/Microsoft.MachineLearningServices/workspaces/AML/runs/ab5354f8-0dee-456f-b706-9cad66aacd39/spans\n",
      ">>>   2021/03/20 06:01:21 Container ssh is not required for job type.\n",
      ">>>   2021/03/20 06:01:21 Starting docker container succeeded.\n",
      ">>>   2021/03/20 06:01:21 Starting docker container succeeded.\n",
      ">>>   2021/03/20 06:01:21 Disk space after starting docker container: 23304MB\n",
      ">>>   2021/03/20 06:01:21 Begin execution of runSpecialJobTask\n",
      ">>>   2021/03/20 06:01:21 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/azureml_compute_logs\n",
      ">>>   2021/03/20 06:01:21 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"f3b75282-fe56-4df3-a122-df8e07c210b5\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/03/20 06:01:21 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/azureml_compute_logs/65_job_prep-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt\n",
      ">>>   2021/03/20 06:01:21 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/azureml_compute_logs/65_job_prep-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt\n",
      ">>>   2021/03/20 06:01:21 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39;/azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"f3b75282-fe56-4df3-a122-df8e07c210b5\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/03/20 06:01:21 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/03/20 06:01:21 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-6f4831c25a1a87b25dee98d1fc6a813d-620762a07991c3be-01 -t ab5354f8-0dee-456f-b706-9cad66aacd39 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/ab5354f8-0dee-456f-b_9501bef5-3040-40c0-ac2e-f4e4fbaebdac/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39;/azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"f3b75282-fe56-4df3-a122-df8e07c210b5\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/03/20 06:01:24 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 1\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:22.391975] Entering job preparation.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:24.271989] Starting job preparation.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:24.272032] Extracting the control code.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:24.299808] fetching and extracting the control code on master node.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:24.299859] Starting extract_project.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:24.299931] Starting to extract zip file.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:25.284610] Finished extracting zip file.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:25.498533] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:25.498618] Start fetching snapshots.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:25.498676] Start fetching snapshot.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:25.498697] Retrieving project from snapshot: f3b75282-fe56-4df3-a122-df8e07c210b5\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 62\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:26.190726] Finished fetching snapshot.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:26.190762] Finished fetching snapshots.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:26.190771] Finished extract_project.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:26.214886] Finished fetching and extracting the control code.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:26.220549] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:26.223420] Start run_history_prep.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:26.291432] Entering context manager injector.\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: Acquired lockfile /tmp/ab5354f8-0dee-456f-b706-9cad66aacd39-datastore.lock to downloading input data references\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:26.885164] downloadDataStore completed\n",
      ">>>   2021/03/20 06:01:27 runSpecialJobTask: preparation: [2021-03-20T06:01:26.888994] Job preparation is complete.\n",
      ">>>   2021/03/20 06:01:27 Execution of runSpecialJobTask completed\n",
      ">>>   2021/03/20 06:01:27 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 3\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/03/20 06:01:27 Process Exiting with Code:  0\n",
      ">>>   2021/03/20 06:01:27 All App Insights Logs was send successfully\n",
      ">>>   \n",
      "2021-03-20T06:01:27Z 127.0.0.1 slots=2 max-slots=2\n",
      "2021-03-20T06:01:27Z launching Custom job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/03/20 06:01:28 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n",
      "2021/03/20 06:01:28 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "[2021-03-20T06:01:30.006226] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['prep_diabetes.py', '--input-data', '49613de8-23eb-409d-bdc7-86856f3a93bd', '--prepped-data', '/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/prepped_data_folder'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 118\n",
      "2021/03/20 06:01:33 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "[2021-03-20T06:01:34.459388] Entering Run History Context Manager.\n",
      "[2021-03-20T06:01:35.517449] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39\n",
      "[2021-03-20T06:01:35.518169] Preparing to call script [prep_diabetes.py] with arguments:['--input-data', '49613de8-23eb-409d-bdc7-86856f3a93bd', '--prepped-data', '/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/prepped_data_folder']\n",
      "[2021-03-20T06:01:35.518276] After variable expansion, calling script [prep_diabetes.py] with arguments:['--input-data', '49613de8-23eb-409d-bdc7-86856f3a93bd', '--prepped-data', '/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/mounts/workspaceblobstore/azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/prepped_data_folder']\n",
      "\n",
      "Loading Data...\n",
      "Saving Data...\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 118\n",
      "\n",
      "\n",
      "[2021-03-20T06:01:50.828113] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.17668557167053223 seconds\n",
      "[2021-03-20T06:01:51.607980] Finished context manager injector.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt\n",
      "===============================================================================================================\n",
      "[2021-03-20T06:01:57.072560] Entering job release\n",
      "[2021-03-20T06:01:58.025058] Starting job release\n",
      "[2021-03-20T06:01:58.025539] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 348\n",
      "[2021-03-20T06:01:58.025839] job release stage : upload_datastore starting...\n",
      "[2021-03-20T06:01:58.035301] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-03-20T06:01:58.035349] job release stage : execute_job_release starting...\n",
      "[2021-03-20T06:01:58.035974] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-03-20T06:01:58.036049] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-03-20T06:01:58.036964] Entering context manager injector.\n",
      "[2021-03-20T06:01:58.255723] job release stage : upload_datastore completed...\n",
      "[2021-03-20T06:01:58.339235] job release stage : execute_job_release completed...\n",
      "[2021-03-20T06:01:58.365159] job release stage : send_run_telemetry starting...\n",
      "[2021-03-20T06:01:58.731814] get vm size and vm region successfully.\n",
      "[2021-03-20T06:01:58.999873] get compute meta data successfully.\n",
      "[2021-03-20T06:01:59.339608] post artifact meta request successfully.\n",
      "[2021-03-20T06:01:59.375558] upload compute record artifact successfully.\n",
      "[2021-03-20T06:01:59.565526] job release stage : send_run_telemetry completed...\n",
      "[2021-03-20T06:01:59.566176] Job release is complete\n",
      "\n",
      "StepRun(Prepare Data) Execution Summary\n",
      "========================================\n",
      "StepRun( Prepare Data ) Status: Finished\n",
      "{'runId': 'ab5354f8-0dee-456f-b706-9cad66aacd39', 'target': 'LC-ML-Cluster-1', 'status': 'Completed', 'startTimeUtc': '2021-03-20T05:59:48.170396Z', 'endTimeUtc': '2021-03-20T06:02:12.859006Z', 'properties': {'ContentSnapshotId': 'f3b75282-fe56-4df3-a122-df8e07c210b5', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '4adac236-318c-40fb-8876-b62c81d6f157', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '2933ce2d', 'azureml.pipelinerunid': '839bcf5f-efd9-4cc6-b8a7-e2811a5f5139', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '49613de8-23eb-409d-bdc7-86856f3a93bd'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'runDefinition': {'script': 'prep_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', '$AZUREML_DATAREFERENCE_prepped_data_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'LC-ML-Cluster-1', 'dataReferences': {'prepped_data_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/prepped_data_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '49613de8-23eb-409d-bdc7-86856f3a93bd', 'name': None, 'version': '1'}, 'dataPath': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'diabetes-pipeline-env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults', 'azureml-dataprep[pandas]', 'pyarrow']}, 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip'], 'name': 'azureml_37123770cfa02a1fe00f423fa57ee472'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210220.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=2gpaIHK9G1PPIo4WE4LWuWMyaY5Z17HtanqLiV%2F5OJs%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/55_azureml-execution-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt?sv=2019-02-02&sr=b&sig=B2vp67%2F8g76CTRVK63XNt%2BMy7iUNKdyOjSFmDlf2M0U%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'azureml-logs/65_job_prep-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/65_job_prep-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt?sv=2019-02-02&sr=b&sig=I1EVEQKhGjsiTsnjiMTgKW%2BtKzuilu7ixNRQ3bwzMDE%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=ejpr0SJomiFcitFuPF4xiFvgM2UcTrjR4noGFmW7J%2Bg%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'azureml-logs/75_job_post-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/75_job_post-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt?sv=2019-02-02&sr=b&sig=2guy%2BiBpQLz%2FdVOXunDl%2Bsdrhe8G05hhJGuQ32yuK2o%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'azureml-logs/process_info.json': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=e3KFfwuOi3Yhrg6qbvmYakEdsIzkszRh5ThCOz8TjcU%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'azureml-logs/process_status.json': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=wyK%2BcROEUlG1L7wWTTV%2FKrK5IW9OqwClA5igf%2BVUvMs%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/118_azureml.log': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/118_azureml.log?sv=2019-02-02&sr=b&sig=Q30P5fKleBOIX%2BtlzYaT9S7fbJ2Xq3oPV7ZVn0hF53U%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=C%2BVttxdBdndD768EdWgTZDNoeC5IUa%2FZpTrvrjoNNO4%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=q36uh5oLe9tYZXCbocXLUrj2t9x2joRimQS6KSUFR2U%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=g4KRyKj%2BkRjRbPhXRo37l533RgUvZDcEOZrP8BKCKBE%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=q4yxYK9%2FKpTr5FbUqXezfXGVapNoZhLj%2FaVSvbWzJjk%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=0gafLVuD9rdErP1fuPw8OEAwuoeBm137ffR54bIxbWY%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=1RtohD7jJFVefV5NpVkaSaM2zrfN0qyezFXxsdG%2BeE8%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=MjNzCmNogiAdki0hmDPobsBxsj4ek%2Faf44X8M36aoD4%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r'}, 'submittedBy': 'Liam Croash'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 883b2975-6847-4f4d-9f4c-ad8e1f619fdd\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/mslearn-diabetes-pipeline/runs/883b2975-6847-4f4d-9f4c-ad8e1f619fdd?wsid=/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourcegroups/ML/workspaces/AML\n",
      "StepRun( Train and Register Model ) Status: NotStarted\n",
      "StepRun( Train and Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt\n",
      "========================================================================================================================\n",
      "2021-03-20T06:02:32Z Starting output-watcher...\n",
      "2021-03-20T06:02:32Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-03-20T06:02:32Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2021-03-20T06:02:33Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25\n",
      "Digest: sha256:5c4d65be8a1ac024c92c7ee4b1f2f84cb18730527e6b5d6dad14058668b79459\n",
      "Status: Image is up to date for 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25:latest\n",
      "05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25:latest\n",
      "2021-03-20T06:02:34Z Check if container 883b2975-6847-4f4d-9f4c-ad8e1f619fdd already exist exited with 0, \n",
      "\n",
      "2fadf3a6abfb96f374ea1973b9642eebac1d4b2fe5e86430b9f008811f259a8e\n",
      "2021/03/20 06:02:39 Starting App Insight Logger for task:  containerSetup\n",
      "2021/03/20 06:02:39 Version: 3.0.01524.0008 Branch: .SourceBranch Commit: eba29f9\n",
      "2021/03/20 06:02:39 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/03/20 06:02:39 Starting infiniband setup\n",
      "2021/03/20 06:02:39 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/03/20 06:02:39 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/03/20 06:02:39 Starting setupPasswordLessSSH setup\n",
      "2021/03/20 06:02:39 sshd runtime has already been installed in the container\n",
      "ssh-keygen: /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "2021/03/20 06:02:40 All App Insights Logs was send successfully\n",
      "2021/03/20 06:02:40 App Insight Client has already been closed\n",
      "2021/03/20 06:02:40 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-03-20T06:02:40Z Starting docker container succeeded.\n",
      "2021-03-20T06:02:45Z Job environment preparation succeeded on 10.0.0.5. Output: \n",
      ">>>   2021/03/20 06:02:29 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2021/03/20 06:02:29 Version: 3.0.01524.0008 Branch: .SourceBranch Commit: eba29f9\n",
      ">>>   2021/03/20 06:02:29 runtime.GOOS linux\n",
      ">>>   2021/03/20 06:02:29 Reading dyanamic configs\n",
      ">>>   2021/03/20 06:02:29 Container sas url: https://baiscriptswesteuropeprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=9UBH7ig8b9NIeIkNQpNxDmP7wUMtSqFoIE5AY22cheE%3D\n",
      ">>>   2021/03/20 06:02:29 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables: no such file or directory\n",
      ">>>   2021/03/20 06:02:29 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installed false, isEnable false,\n",
      ">>>   2021/03/20 06:02:29 azsecpack isEnable:false,GetDisableVsatlsscan:true\n",
      ">>>   2021/03/20 06:02:29 [doTurnOffAzsecpack] output:   Active: inactive (dead)\n",
      ">>>   ,err:<nil>.\n",
      ">>>   2021/03/20 06:02:29 OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2021/03/20 06:02:29 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
      ">>>   2021/03/20 06:02:29 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/03/20 06:02:29 GPU count found on the node: 0\n",
      ">>>   2021/03/20 06:02:29 AMLComputeXDSEndpoint:  https://westeurope-prodk8ds.batchai.core.windows.net\n",
      ">>>   2021/03/20 06:02:29 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2021/03/20 06:02:29 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/config\n",
      ">>>   2021/03/20 06:02:29 This is not a aml-workstation (compute instance), current offer type: azureml. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2021/03/20 06:02:29 Starting identity responder.\n",
      ">>>   2021/03/20 06:02:29 Starting identity responder.\n",
      ">>>   2021/03/20 06:02:29 Failed to open file /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/config/.batchai.IdentityResponder.envlist: open /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
      ">>>   2021/03/20 06:02:29 Logfile used for identity responder: /mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/IdentityResponderLog-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt\n",
      ">>>   2021/03/20 06:02:29 Logfile used for identity responder: /mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/IdentityResponderLog-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt\n",
      ">>>   2021/03/20 06:02:29 Started Identity Responder for job.\n",
      ">>>   2021/03/20 06:02:29 Started Identity Responder for job.\n",
      ">>>   2021/03/20 06:02:29 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/wd\n",
      ">>>   2021/03/20 06:02:29 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/shared\n",
      ">>>   2021/03/20 06:02:29 Mounting job level file systems\n",
      ">>>   2021/03/20 06:02:29 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts\n",
      ">>>   2021/03/20 06:02:29 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/config/.amlcompute.datastorecredentials\n",
      ">>>   2021/03/20 06:02:29 Datastore credentials file not found, skipping.\n",
      ">>>   2021/03/20 06:02:29 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/config/.master.runtimesastokens\n",
      ">>>   2021/03/20 06:02:29 Runtime sas tokens file not found, skipping.\n",
      ">>>   2021/03/20 06:02:29 No NFS configured\n",
      ">>>   2021/03/20 06:02:29 No Azure File Shares configured\n",
      ">>>   2021/03/20 06:02:29 Mounting blob file systems\n",
      ">>>   2021/03/20 06:02:29 Blobfuse runtime version 1.3.6\n",
      ">>>   2021/03/20 06:02:29 Mounting azureml-blobstore-05ae1289-f7d6-4452-89be-e0b8433bc9bc container from aml1914939045 account at /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore\n",
      ">>>   2021/03/20 06:02:29 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/03/20 06:02:29 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/03/20 06:02:29 Blobfuse cache size set to 21850 MB.\n",
      ">>>   2021/03/20 06:02:29 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=21850 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/03/20 06:02:29 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore\n",
      ">>>   2021/03/20 06:02:29 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore\n",
      ">>>   2021/03/20 06:02:29 Successfully mounted azureml-blobstore-05ae1289-f7d6-4452-89be-e0b8433bc9bc container from aml1914939045 account at /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore\n",
      ">>>   2021/03/20 06:02:29 No unmanaged file systems configured\n",
      ">>>   2021/03/20 06:02:29 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/03/20 06:02:29 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/03/20 06:02:29 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml_compute_logs\n",
      ">>>   2021/03/20 06:02:31 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/logs\n",
      ">>>   2021/03/20 06:02:32 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/outputs\n",
      ">>>   2021/03/20 06:02:32 Starting output-watcher...\n",
      ">>>   2021/03/20 06:02:32 Single file input dataset is enabled.\n",
      ">>>   2021/03/20 06:02:32 Start to pulling docker image: 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25\n",
      ">>>   2021/03/20 06:02:32 Start pull docker image: 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io\n",
      ">>>   2021/03/20 06:02:32 Getting credentials for image 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25 with url 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io\n",
      ">>>   2021/03/20 06:02:32 Container registry is ACR.\n",
      ">>>   2021/03/20 06:02:32 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/03/20 06:02:32 Getting ACR Credentials from EMS for environment diabetes-pipeline-env:1\n",
      ">>>   2021/03/20 06:02:32 Requesting XDS for registry details.\n",
      ">>>   2021/03/20 06:02:32 Attempt 1 of http call to https://westeurope-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourceGroups/ml/workspaces/aml/clusters/lc-ml-cluster-1/nodes/tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d?api-version=2018-02-01\n",
      ">>>   2021/03/20 06:02:32 Got container registry details from credentials service for registry address: 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io.\n",
      ">>>   2021/03/20 06:02:32 Writing ACR Details to file...\n",
      ">>>   2021/03/20 06:02:32 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/03/20 06:02:32 Executing 'Copy ACR Details file' on 10.0.0.5\n",
      ">>>   2021/03/20 06:02:33 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/03/20 06:02:33 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/03/20 06:02:33 Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/03/20 06:02:33 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/03/20 06:02:33 EMS returned 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io for environment diabetes-pipeline-env\n",
      ">>>   2021/03/20 06:02:33 start login to the docker registry\n",
      ">>>   2021/03/20 06:02:33 Successfully logged into the docker registry.\n",
      ">>>   2021/03/20 06:02:33 Start run pull docker image command\n",
      ">>>   2021/03/20 06:02:33 Pull docker image succeeded.\n",
      ">>>   2021/03/20 06:02:33 Pull docker image time: 1.018420578s\n",
      ">>>   \n",
      ">>>   2021/03/20 06:02:33 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/03/20 06:02:33 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/03/20 06:02:34 Setting the memory limit for docker container to be 13675 MB\n",
      ">>>   2021/03/20 06:02:34 The env variable file size is 37257 bytes\n",
      ">>>   2021/03/20 06:02:34 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/03/20 06:02:34 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,883b2975-6847-4f4d-9f4c-ad8e1f619fdd,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/certs:/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,13675m,-v,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/wd:/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd:/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/config/.batchai.envlist,--shm-size,2g\n",
      ">>>   2021/03/20 06:02:34 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
      ">>>   2021/03/20 06:02:34 the binding /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd:/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd \n",
      ">>>   2021/03/20 06:02:34 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,883b2975-6847-4f4d-9f4c-ad8e1f619fdd,-m,13675m,-w,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/config/.batchai.envlist,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd:/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd,-v,/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/wd:/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/wd,-v,/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/certs:/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/certs\n",
      ">>>   2021/03/20 06:02:34 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 883b2975-6847-4f4d-9f4c-ad8e1f619fdd -m 13675m -w /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/config/.batchai.envlist --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd:/mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd -v /mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/wd:/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/wd -v /mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/certs:/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/certs -d -it --privileged --net=host 05ae1289f7d6445289bee0b8433bc9bc.azurecr.io/azureml/azureml_19fd5701317efa7d61a4f1cb3e8efe25\n",
      ">>>   2021/03/20 06:02:34 Attempt 1 of http call to https://westeurope.experiments.azureml.net/history/v1.0/private/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourceGroups/ML/providers/Microsoft.MachineLearningServices/workspaces/AML/runs/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/spans\n",
      ">>>   2021/03/20 06:02:34 Check if container 883b2975-6847-4f4d-9f4c-ad8e1f619fdd already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/03/20 06:02:34 Check if container 883b2975-6847-4f4d-9f4c-ad8e1f619fdd already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/03/20 06:02:40 Container ssh is not required for job type.\n",
      ">>>   2021/03/20 06:02:40 Starting docker container succeeded.\n",
      ">>>   2021/03/20 06:02:40 Starting docker container succeeded.\n",
      ">>>   2021/03/20 06:02:40 Disk space after starting docker container: 23303MB\n",
      ">>>   2021/03/20 06:02:40 Begin execution of runSpecialJobTask\n",
      ">>>   2021/03/20 06:02:40 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml_compute_logs\n",
      ">>>   2021/03/20 06:02:40 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"f3b75282-fe56-4df3-a122-df8e07c210b5\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/03/20 06:02:40 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml_compute_logs/65_job_prep-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt\n",
      ">>>   2021/03/20 06:02:40 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml_compute_logs/65_job_prep-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt\n",
      ">>>   2021/03/20 06:02:40 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd;/azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"f3b75282-fe56-4df3-a122-df8e07c210b5\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/03/20 06:02:40 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/03/20 06:02:40 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-203813e806cef08a19692d36f101e22a-241e022f081fb6ba-01 -t 883b2975-6847-4f4d-9f4c-ad8e1f619fdd bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/a804dcc5-53eb-4701-9026-63ff84fd20e9/job-1/883b2975-6847-4f4d-9_398e3df1-4018-4ded-8337-6dcded3274f6/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd;/azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python /mnt/batch/tasks/shared/LS_root/jobs/aml/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd/mounts/workspaceblobstore/azureml/883b2975-6847-4f4d-9f4c-ad8e1f619fdd-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"f3b75282-fe56-4df3-a122-df8e07c210b5\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/03/20 06:02:44 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 1\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:40.918055] Entering job preparation.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:42.629005] Starting job preparation.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:42.629044] Extracting the control code.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:42.656613] fetching and extracting the control code on master node.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:42.656654] Starting extract_project.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:42.656703] Starting to extract zip file.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:43.728117] Finished extracting zip file.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:43.949756] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:43.949829] Start fetching snapshots.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:43.949884] Start fetching snapshot.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:43.949906] Retrieving project from snapshot: f3b75282-fe56-4df3-a122-df8e07c210b5\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 59\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:44.411033] Finished fetching snapshot.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:44.411066] Finished fetching snapshots.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:44.411072] Finished extract_project.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:44.425791] Finished fetching and extracting the control code.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:44.429454] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:44.431298] Start run_history_prep.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:44.496510] Entering context manager injector.\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: Acquired lockfile /tmp/883b2975-6847-4f4d-9f4c-ad8e1f619fdd-datastore.lock to downloading input data references\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:45.117119] downloadDataStore completed\n",
      ">>>   2021/03/20 06:02:45 runSpecialJobTask: preparation: [2021-03-20T06:02:45.120107] Job preparation is complete.\n",
      ">>>   2021/03/20 06:02:45 Execution of runSpecialJobTask completed\n",
      ">>>   2021/03/20 06:02:45 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 3\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/03/20 06:02:45 Process Exiting with Code:  0\n",
      ">>>   2021/03/20 06:02:45 All App Insights Logs was send successfully\n",
      ">>>   \n",
      "2021-03-20T06:02:45Z 127.0.0.1 slots=2 max-slots=2\n",
      "2021-03-20T06:02:46Z launching Custom job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt\n",
      "===============================================================================================================\n",
      "[2021-03-20T06:03:02.194190] Entering job release\n",
      "[2021-03-20T06:03:03.257116] Starting job release\n",
      "[2021-03-20T06:03:03.263115] Logging experiment finalizing status in history service.\n",
      "[2021-03-20T06:03:03.263289] job release stage : upload_datastore starting...\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 171\n",
      "[2021-03-20T06:03:03.263818] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-03-20T06:03:03.264013] job release stage : execute_job_release starting...\n",
      "[2021-03-20T06:03:03.267636] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-03-20T06:03:03.267715] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-03-20T06:03:03.279488] Entering context manager injector.\n",
      "[2021-03-20T06:03:03.488913] job release stage : upload_datastore completed...\n",
      "[2021-03-20T06:03:03.559767] job release stage : send_run_telemetry starting...\n",
      "[2021-03-20T06:03:03.605225] job release stage : execute_job_release completed...\n",
      "[2021-03-20T06:03:03.817045] get vm size and vm region successfully.\n",
      "[2021-03-20T06:03:04.102477] get compute meta data successfully.\n",
      "[2021-03-20T06:03:04.268648] post artifact meta request successfully.\n",
      "[2021-03-20T06:03:04.313837] upload compute record artifact successfully.\n",
      "[2021-03-20T06:03:04.526039] job release stage : send_run_telemetry completed...\n",
      "[2021-03-20T06:03:04.526701] Job release is complete\n",
      "\n",
      "StepRun(Train and Register Model) Execution Summary\n",
      "====================================================\n",
      "StepRun( Train and Register Model ) Status: Finished\n",
      "{'runId': '883b2975-6847-4f4d-9f4c-ad8e1f619fdd', 'target': 'LC-ML-Cluster-1', 'status': 'Completed', 'startTimeUtc': '2021-03-20T06:02:29.976023Z', 'endTimeUtc': '2021-03-20T06:03:13.942861Z', 'properties': {'ContentSnapshotId': 'f3b75282-fe56-4df3-a122-df8e07c210b5', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '685c2d40-34f2-499b-a252-ca5d59b7c494', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '8d07ea08', 'azureml.pipelinerunid': '839bcf5f-efd9-4cc6-b8a7-e2811a5f5139', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'train_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--training-folder', '$AZUREML_DATAREFERENCE_prepped_data_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'LC-ML-Cluster-1', 'dataReferences': {'prepped_data_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/prepped_data_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'diabetes-pipeline-env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults', 'azureml-dataprep[pandas]', 'pyarrow']}, 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip'], 'name': 'azureml_37123770cfa02a1fe00f423fa57ee472'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210220.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml-logs/55_azureml-execution-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt?sv=2019-02-02&sr=b&sig=mj5%2Fx0lGaZZQY7d3ADUg%2BL7VsIFW7s6%2Fo4%2F7VazBKAs%3D&st=2021-03-20T05%3A53%3A03Z&se=2021-03-20T14%3A03%3A03Z&sp=r', 'azureml-logs/65_job_prep-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml-logs/65_job_prep-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt?sv=2019-02-02&sr=b&sig=dDycST%2FL7SuGSaIQdW3I6dhu8plIH0bOvvXlmCgOjmo%3D&st=2021-03-20T05%3A53%3A03Z&se=2021-03-20T14%3A03%3A03Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=tpSqd3QhH6s5HbcVqg6GCCM%2BMAK07vEo95YBrwhsjFc%3D&st=2021-03-20T05%3A53%3A03Z&se=2021-03-20T14%3A03%3A03Z&sp=r', 'azureml-logs/75_job_post-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml-logs/75_job_post-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt?sv=2019-02-02&sr=b&sig=YHOZ0U1%2FRbTcY0rZJxpg1VzEYZ%2Bew3Qt49rWMh4eviI%3D&st=2021-03-20T05%3A53%3A03Z&se=2021-03-20T14%3A03%3A03Z&sp=r', 'azureml-logs/process_info.json': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=r9t7n9%2ByEtOjyqxOARRpAgHCUnlc8tw0%2Fg8y3aq%2Faiw%3D&st=2021-03-20T05%3A53%3A03Z&se=2021-03-20T14%3A03%3A03Z&sp=r', 'azureml-logs/process_status.json': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.883b2975-6847-4f4d-9f4c-ad8e1f619fdd/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=I9IqRoJeRJR9zMS2n3aaws0S9shyJ5lFWm7VIZqb8nw%3D&st=2021-03-20T05%3A53%3A03Z&se=2021-03-20T14%3A03%3A03Z&sp=r', 'logs/azureml/113_azureml.log': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.883b2975-6847-4f4d-9f4c-ad8e1f619fdd/logs/azureml/113_azureml.log?sv=2019-02-02&sr=b&sig=jXY682B%2BZZphXFpRRjDNlMVAEgghABYNe7QeWKin8u4%3D&st=2021-03-20T05%3A53%3A06Z&se=2021-03-20T14%3A03%3A06Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.883b2975-6847-4f4d-9f4c-ad8e1f619fdd/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=7fZG%2FQTyJfylySFNVsLYHeGN%2BVAEZTjSHpz4tRkxBFk%3D&st=2021-03-20T05%3A53%3A06Z&se=2021-03-20T14%3A03%3A06Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.883b2975-6847-4f4d-9f4c-ad8e1f619fdd/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=P8xHv6UePOtZ%2BUuQRAM5ktPwWXgRvgzEFSgxnPj38Yo%3D&st=2021-03-20T05%3A53%3A06Z&se=2021-03-20T14%3A03%3A06Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.883b2975-6847-4f4d-9f4c-ad8e1f619fdd/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=shLkz1KuMrhSoUPYO0pfc1GlObmiXXsgAbr9lpUmSf4%3D&st=2021-03-20T05%3A53%3A06Z&se=2021-03-20T14%3A03%3A06Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.883b2975-6847-4f4d-9f4c-ad8e1f619fdd/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=EmyHO5TsnoQEU%2B2q3hevJay0%2FJobrssjHuxXiUt0i94%3D&st=2021-03-20T05%3A53%3A06Z&se=2021-03-20T14%3A03%3A06Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.883b2975-6847-4f4d-9f4c-ad8e1f619fdd/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=qZ2QNqUn8w64hALlwJNHQZnzgAGpscWxL891aYwKTHg%3D&st=2021-03-20T05%3A53%3A06Z&se=2021-03-20T14%3A03%3A06Z&sp=r'}, 'submittedBy': 'Liam Croash'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '839bcf5f-efd9-4cc6-b8a7-e2811a5f5139', 'status': 'Completed', 'startTimeUtc': '2021-03-20T05:47:36.744386Z', 'endTimeUtc': '2021-03-20T06:03:18.982022Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.839bcf5f-efd9-4cc6-b8a7-e2811a5f5139/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=Zl4NpNQ7Dnyx8HChhw%2FjWiGyp59SNiH3nbVkZYqcbU0%3D&st=2021-03-20T05%3A38%3A00Z&se=2021-03-20T13%3A48%3A00Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.839bcf5f-efd9-4cc6-b8a7-e2811a5f5139/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=cnmL6DUBAwf9qvUBsKUluVGGicnnmIvQ1H3nMaghfUg%3D&st=2021-03-20T05%3A38%3A00Z&se=2021-03-20T13%3A48%3A00Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.839bcf5f-efd9-4cc6-b8a7-e2811a5f5139/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=n6e6X7sziYJU0%2FpXsm80abdg%2Fd90SMxXhx32iK7k2xM%3D&st=2021-03-20T05%3A38%3A00Z&se=2021-03-20T13%3A48%3A00Z&sp=r'}, 'submittedBy': 'Liam Croash'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [prep_step, train_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graphical representation of the pipeline experiment will be displayed in the widget as it runs. Keep an eye on the kernel indicator at the top right of the page, when it turns from **&#9899;** to **&#9711;**, the code has finished running. You can also monitor pipeline runs in the **Experiments** page in [Azure Machine Learning studio](https://ml.azure.com).\n",
    "\n",
    "When the pipeline has finished, you can examine the metrics recorded by it's child runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Register Model :\n",
      "\t Accuracy : 0.8997777777777778\n",
      "\t AUC : 0.886222229497231\n",
      "\t ROC : aml://artifactId/ExperimentRun/dcid.883b2975-6847-4f4d-9f4c-ad8e1f619fdd/ROC_1616220173.png\n",
      "Prepare Data :\n",
      "\t raw_rows : 15000\n",
      "\t processed_rows : 15000\n"
     ]
    }
   ],
   "source": [
    "for run in pipeline_run.get_children():\n",
    "    print(run.name, ':')\n",
    "    metrics = run.get_metrics()\n",
    "    for metric_name in metrics:\n",
    "        print('\\t',metric_name, \":\", metrics[metric_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the pipeline was successful, a new model should be registered with a *Training context* tag indicating it was trained in a pipeline. Run the following code to verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version: 5\n",
      "\t Training context : Pipeline\n",
      "\t AUC : 0.886222229497231\n",
      "\t Accuracy : 0.8997777777777778\n",
      "\n",
      "\n",
      "diabetes_model version: 4\n",
      "\t Training context : File dataset\n",
      "\t AUC : 0.856863734857782\n",
      "\t Accuracy : 0.7893333333333333\n",
      "\n",
      "\n",
      "diabetes_model version: 3\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568520112794097\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 2\n",
      "\t Training context : Parameterized script\n",
      "\t AUC : 0.8484048957659586\n",
      "\t Accuracy : 0.7736666666666666\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t Training context : Script\n",
      "\t AUC : 0.848370565699786\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "amlstudio-predict-diabetes version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "amlstudio-predict-penguin-clus version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "amlstudio-predict-auto-price version: 1\n",
      "\t CreatedByAMLStudio : true\n",
      "\n",
      "\n",
      "AutoML829737c9d0 version: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the pipeline\n",
    "\n",
    "After you've created and tested a pipeline, you can publish it as a REST service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>diabetes-training-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/4eedcf45-e37f-453e-a1ad-a34bcdda3a1b?wsid=/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourcegroups/ML/workspaces/AML\" target=\"_blank\" rel=\"noopener\">4eedcf45-e37f-453e-a1ad-a34bcdda3a1b</a></td><td>Active</td><td><a href=\"https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourceGroups/ML/providers/Microsoft.MachineLearningServices/workspaces/AML/PipelineRuns/PipelineSubmit/4eedcf45-e37f-453e-a1ad-a34bcdda3a1b\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: diabetes-training-pipeline,\n",
       "Id: 4eedcf45-e37f-453e-a1ad-a34bcdda3a1b,\n",
       "Status: Active,\n",
       "Endpoint: https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourceGroups/ML/providers/Microsoft.MachineLearningServices/workspaces/AML/PipelineRuns/PipelineSubmit/4eedcf45-e37f-453e-a1ad-a34bcdda3a1b)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Publish the pipeline from the run\n",
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"diabetes-training-pipeline\", description=\"Trains diabetes model\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the published pipeline has an endpoint, which you can see in the **Endpoints** page (on the **Pipeline Endpoints** tab) in [Azure Machine Learning studio](https://ml.azure.com). You can also find its URI as a property of the published pipeline object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourceGroups/ML/providers/Microsoft.MachineLearningServices/workspaces/AML/PipelineRuns/PipelineSubmit/4eedcf45-e37f-453e-a1ad-a34bcdda3a1b\n"
     ]
    }
   ],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the pipeline endpoint\n",
    "\n",
    "To use the endpoint, client applications need to make a REST call over HTTP. This request must be authenticated, so an authorization header is required. A real application would require a service principal with which to be authenticated, but to test this out, we'll use the authorization header from your current connection to your Azure workspace, which you can get using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication header ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print(\"Authentication header ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to call the REST interface. The pipeline runs asynchronously, so we'll get an identifier back, which we can use to track the pipeline experiment as it runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6093abe0-9655-4a18-a602-9ea7a7fd6a83'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "experiment_name = 'mslearn-diabetes-pipeline'\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you have the run ID, you can use it to wait for the run to complete.\n",
    "\n",
    "> **Note**: The pipeline should complete quickly, because each step was configured to allow output reuse. This was done primarily for convenience and to save time in this course. In reality, you'd likely want the first step to run every time in case the data has changed, and trigger the subsequent steps only if the output from step one changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 6093abe0-9655-4a18-a602-9ea7a7fd6a83\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/mslearn-diabetes-pipeline/runs/6093abe0-9655-4a18-a602-9ea7a7fd6a83?wsid=/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourcegroups/ML/workspaces/AML\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 157b7df1-205e-4156-8c9d-fc7c195ff2c0\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/mslearn-diabetes-pipeline/runs/157b7df1-205e-4156-8c9d-fc7c195ff2c0?wsid=/subscriptions/a0d35038-9212-4eca-88f1-682726afa75c/resourcegroups/ML/workspaces/AML\n",
      "\n",
      "StepRun(Prepare Data) Execution Summary\n",
      "========================================\n",
      "StepRun( Prepare Data ) Status: Finished\n",
      "{'runId': '157b7df1-205e-4156-8c9d-fc7c195ff2c0', 'target': 'LC-ML-Cluster-1', 'status': 'Completed', 'startTimeUtc': '2021-03-20T06:03:40.60178Z', 'endTimeUtc': '2021-03-20T06:03:40.711152Z', 'properties': {'azureml.reusedrunid': 'ab5354f8-0dee-456f-b706-9cad66aacd39', 'azureml.reusednodeid': '2933ce2d', 'azureml.reusedpipeline': '839bcf5f-efd9-4cc6-b8a7-e2811a5f5139', 'azureml.reusedpipelinerunid': '839bcf5f-efd9-4cc6-b8a7-e2811a5f5139', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '2933ce2d', 'ContentSnapshotId': 'f3b75282-fe56-4df3-a122-df8e07c210b5', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '4adac236-318c-40fb-8876-b62c81d6f157', 'azureml.pipelinerunid': '6093abe0-9655-4a18-a602-9ea7a7fd6a83', 'azureml.pipelineid': '4eedcf45-e37f-453e-a1ad-a34bcdda3a1b', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'prep_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', '$AZUREML_DATAREFERENCE_prepped_data_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'LC-ML-Cluster-1', 'dataReferences': {'prepped_data_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/ab5354f8-0dee-456f-b706-9cad66aacd39/prepped_data_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '49613de8-23eb-409d-bdc7-86856f3a93bd', 'name': None, 'version': '1'}, 'dataPath': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'diabetes-pipeline-env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults', 'azureml-dataprep[pandas]', 'pyarrow']}, 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip'], 'name': 'azureml_37123770cfa02a1fe00f423fa57ee472'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210220.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=2gpaIHK9G1PPIo4WE4LWuWMyaY5Z17HtanqLiV%2F5OJs%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/55_azureml-execution-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt?sv=2019-02-02&sr=b&sig=B2vp67%2F8g76CTRVK63XNt%2BMy7iUNKdyOjSFmDlf2M0U%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'azureml-logs/65_job_prep-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/65_job_prep-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt?sv=2019-02-02&sr=b&sig=I1EVEQKhGjsiTsnjiMTgKW%2BtKzuilu7ixNRQ3bwzMDE%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=ejpr0SJomiFcitFuPF4xiFvgM2UcTrjR4noGFmW7J%2Bg%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'azureml-logs/75_job_post-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/75_job_post-tvmps_87a51eff835d4e1be6b19d1826393d2ea43b09f62ed6239b6a17a92aa49334be_d.txt?sv=2019-02-02&sr=b&sig=2guy%2BiBpQLz%2FdVOXunDl%2Bsdrhe8G05hhJGuQ32yuK2o%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'azureml-logs/process_info.json': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=e3KFfwuOi3Yhrg6qbvmYakEdsIzkszRh5ThCOz8TjcU%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'azureml-logs/process_status.json': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=wyK%2BcROEUlG1L7wWTTV%2FKrK5IW9OqwClA5igf%2BVUvMs%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/118_azureml.log': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/118_azureml.log?sv=2019-02-02&sr=b&sig=Q30P5fKleBOIX%2BtlzYaT9S7fbJ2Xq3oPV7ZVn0hF53U%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=C%2BVttxdBdndD768EdWgTZDNoeC5IUa%2FZpTrvrjoNNO4%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=q36uh5oLe9tYZXCbocXLUrj2t9x2joRimQS6KSUFR2U%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=g4KRyKj%2BkRjRbPhXRo37l533RgUvZDcEOZrP8BKCKBE%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=q4yxYK9%2FKpTr5FbUqXezfXGVapNoZhLj%2FaVSvbWzJjk%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=0gafLVuD9rdErP1fuPw8OEAwuoeBm137ffR54bIxbWY%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=1RtohD7jJFVefV5NpVkaSaM2zrfN0qyezFXxsdG%2BeE8%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.ab5354f8-0dee-456f-b706-9cad66aacd39/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=MjNzCmNogiAdki0hmDPobsBxsj4ek%2Faf44X8M36aoD4%3D&st=2021-03-20T05%3A52%3A00Z&se=2021-03-20T14%3A02%3A00Z&sp=r'}, 'submittedBy': 'Liam Croash'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '6093abe0-9655-4a18-a602-9ea7a7fd6a83', 'status': 'Completed', 'startTimeUtc': '2021-03-20T06:03:38.601389Z', 'endTimeUtc': '2021-03-20T06:03:41.288892Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.pipelineid': '4eedcf45-e37f-453e-a1ad-a34bcdda3a1b'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.6093abe0-9655-4a18-a602-9ea7a7fd6a83/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=ZQl%2F5%2FIwroDRLy8s5mdbbMZVAFuQ4mimslC7yTrGAbc%3D&st=2021-03-20T05%3A53%3A44Z&se=2021-03-20T14%3A03%3A44Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.6093abe0-9655-4a18-a602-9ea7a7fd6a83/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=0bECt0QyTv3kFgex%2Bw%2FWP4cD8002Pignq6FvJUHQ9Ts%3D&st=2021-03-20T05%3A53%3A44Z&se=2021-03-20T14%3A03%3A44Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://aml1914939045.blob.core.windows.net/azureml/ExperimentRun/dcid.6093abe0-9655-4a18-a602-9ea7a7fd6a83/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=vC9XrIHRGU8tjvQg14NViY0KfdzxsWEbCzR6yJNi%2BWc%3D&st=2021-03-20T05%3A53%3A44Z&se=2021-03-20T14%3A03%3A44Z&sp=r'}, 'submittedBy': 'Liam Croash'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
    "published_pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule the Pipeline\n",
    "\n",
    "Suppose the clinic for the diabetes patients collects new data each week, and adds it to the dataset. You could run the pipeline every week to retrain the model with the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline scheduled.\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
    "\n",
    "# Submit the Pipeline every Monday at 00:00 UTC\n",
    "recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, week_days=[\"Monday\"], time_of_day=\"00:00\")\n",
    "weekly_schedule = Schedule.create(ws, name=\"weekly-diabetes-training\", \n",
    "                                  description=\"Based on time\",\n",
    "                                  pipeline_id=published_pipeline.id, \n",
    "                                  experiment_name='mslearn-diabetes-pipeline', \n",
    "                                  recurrence=recurrence)\n",
    "print('Pipeline scheduled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve the schedules that are defined in the workspace like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pipeline(Name: weekly-diabetes-training,\n",
       " Id: 1dcd9b25-e1ac-47fd-a5f6-bc422ca0151b,\n",
       " Status: Active,\n",
       " Pipeline Id: 4eedcf45-e37f-453e-a1ad-a34bcdda3a1b,\n",
       " Pipeline Endpoint Id: None,\n",
       " Recurrence Details: Runs at 0:00 on Monday every Week)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedules = Schedule.list(ws)\n",
    "schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the latest run like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_experiment = ws.experiments.get('mslearn-diabetes-pipeline')\n",
    "latest_run = list(pipeline_experiment.get_runs())[0]\n",
    "\n",
    "latest_run.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example, designed to demonstrate the principle. In reality, you could build more sophisticated logic into the pipeline steps - for example, evaluating the model against some test data to calculate a performance metric like AUC or accuracy, comparing the metric to that of any previously registered versions of the model, and only registering the new model if it performs better.\n",
    "\n",
    "You can use the [Azure Machine Learning extension for Azure DevOps](https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml) to combine Azure ML pipelines with Azure DevOps pipelines (yes, it *is* confusing that they have the same name!) and integrate model retraining into a *continuous integration/continuous deployment (CI/CD)* process. For example you could use an Azure DevOps *build* pipeline to trigger an Azure ML pipeline that trains and registers a model, and when the model is registered it could trigger an Azure Devops *release* pipeline that deploys the model as a web service, along with the application or service that consumes the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
